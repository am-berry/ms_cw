{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Device-Checks\" data-toc-modified-id=\"Device-Checks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Device Checks</a></span></li><li><span><a href=\"#Environment-Set-up\" data-toc-modified-id=\"Environment-Set-up-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment Set-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-States\" data-toc-modified-id=\"Preprocessing-States-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Preprocessing States</a></span></li></ul></li><li><span><a href=\"#Experience-Replay\" data-toc-modified-id=\"Experience-Replay-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Experience Replay</a></span></li><li><span><a href=\"#Double-Deep-Q-Learning-Agent\" data-toc-modified-id=\"Double-Deep-Q-Learning-Agent-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Double Deep-Q-Learning Agent</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "## CHECK AVAILABLE GPUs\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7906642321543762764\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8441178619956984470\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6515012665\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18404827236774535127\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11089946355844863781\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "## PRINT DEVICE DETAILS\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES\n",
    "import gym\n",
    "from gym import Wrapper\n",
    "from gym import spaces\n",
    "import retro\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape is (210, 160, 3)\n",
      "\n",
      "Possible actions are 6: \n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "## INITIATE THE ENVIRONMENT\n",
    "env = gym.make(\"SpaceInvaders-v0\")\n",
    "\n",
    "# Print environment details\n",
    "print('State shape is {}\\n'.format(env.observation_space.shape))\n",
    "print('Possible actions are {}: '.format(env.action_space.n))\n",
    "print(env.env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20613213c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "frame = env.reset()\n",
    "plt.imshow(frame, interpolation='nearest')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "frame = frame[28:196:2, ::2]\n",
    "frame = frame.mean(axis=2)\n",
    "frame = (frame - 128) / 128-1\n",
    "plt.imshow(frame, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A FUNCTION TO PREPROCESS STATES\n",
    "def preprocess_state(state):\n",
    "    \"\"\"Reshape and transform an RGB state to grayscale\"\"\"\n",
    "    # Crop unecessary lives & points pannel and resize the image\n",
    "    state = state[28:196:2, ::2]\n",
    "    # Convert the image to greyscale\n",
    "    state = state.mean(axis=2)\n",
    "    # Normalize the image from -1 to +1\n",
    "    state = (state - 128) / 128-1\n",
    "    return state.reshape(84,80)\n",
    "\n",
    "## CREATE A CLASS THAT MODIFIES THE GYM ENVIRONMENT\n",
    "class Environment(object):\n",
    "    \"\"\"Define environment parameters\"\"\"\n",
    "    def __init__(self, env, stack=4):\n",
    "        self.env = gym.make(env)\n",
    "        self.stack = stack\n",
    "        self.action_space = self.env.action_space\n",
    "        self.actions = range(self.env.action_space.n)\n",
    "        # Screen buffer of size 4 to be able to build state arrays of size [1, 4, 84, 80]\n",
    "        self.state_buffer = deque()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reshape a state into (84,80,1) and produce initial stacked state\"\"\"\n",
    "        # Clear the state buffer\n",
    "        self.state_buffer = deque()\n",
    "        state = self.env.reset()\n",
    "        state = preprocess_state(state)\n",
    "        # Since new episode, copy the same frame 4x\n",
    "        stacked_state = np.stack([state for i in range(self.stack)], axis=0)\n",
    "\n",
    "        # Put first 3 frames in buffer\n",
    "        for i in range(self.stack-1):\n",
    "            self.state_buffer.append(state)\n",
    "            \n",
    "        return stacked_state\n",
    "    \n",
    "    def step(self, action_index):\n",
    "        \"\"\"Concatenate 3 previous states and current state to produce \n",
    "           a stacked state of shape (4,84,80)\"\"\"\n",
    "        state, reward, done, info = self.env.step(self.actions[action_index])\n",
    "        state = preprocess_state(state)\n",
    "        \n",
    "        previous_frames = np.array(self.state_buffer)\n",
    "        stacked_state = np.empty((self.stack, 84, 80))\n",
    "        stacked_state[:self.stack-1, :] = previous_frames\n",
    "        stacked_state[self.stack-1] = state\n",
    "\n",
    "        # Pop the oldest frame and add the current frame to the queue\n",
    "        self.state_buffer.popleft()\n",
    "        self.state_buffer.append(state)\n",
    "\n",
    "        return stacked_state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape is (4, 84, 80)\n",
      "\n",
      "Possible actions are 6: \n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "env = Environment(\"SpaceInvaders-v0\",stack=4)\n",
    "print('State shape is {}\\n'.format(np.shape(env.reset())))\n",
    "print('Possible actions are {}: '.format(env.action_space.n))\n",
    "print(env.env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A CLASS THAT STORES THE AGENT'S EXPERIENCES AND RETRIEVES RANDOM BATCHES FROM ITS MEMORY\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity=10000, batch_size=32):\n",
    "        \"\"\"Define the class parameters\"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.experience = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to the memory buffer\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.buffer.append(e)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)        \n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Sample a random batch of experiences from the memory\"\"\"\n",
    "        samples = random.sample(self.buffer, self.batch_size)\n",
    "\n",
    "        states = np.array([state[0] for state in samples])\n",
    "        actions = np.array([action[1] for action in samples])\n",
    "        rewards = np.array([reward[2] for reward in samples])\n",
    "        next_states = np.array([next_state[3] for next_state in samples])\n",
    "        dones = np.array([done[4] for done in samples])\n",
    "        \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Deep-Q-Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE THE DOUBLE DEEP-Q-LEARNING AGENT\n",
    "class DDQNAgent:\n",
    "\n",
    "    def __init__(self, input_shape, action_space, capacity=10000, batch_size=32, memory_size=1000, \n",
    "                 learning_rate=0.00025, gamma = 0.99, epsilon=1.0, epsilon_min = 0.1, \n",
    "                 epsilon_decay = 0.9999):\n",
    "        \"\"\"Create an instance of a Deep-Q-Network Agent\"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.action_size = action_space.n # number of possible actions\n",
    "        self.learning_rate = learning_rate # model's learning rate\n",
    "        self.gamma = gamma # discount rate\n",
    "        self.batch_size = batch_size # size of batches sampled from memory\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.epsilon_min = epsilon_min # threshold of epsilon\n",
    "        self.epsilon_decay = epsilon_decay # decay of exploration rate\n",
    "        self.model = self.build_model() # instance of dqn model\n",
    "        self.target_model = self.build_model() # target model\n",
    "        self.memory = ReplayMemory(capacity=capacity, batch_size=self.batch_size) # expirience replay memory\n",
    "        self.memory_size = memory_size # threshold of memory size to start training\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"Build the Convolutional DQN model\"\"\"\n",
    "        model = Sequential()\n",
    "        # add convolutional layers\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=self.input_shape,data_format='channels_first')) # provide as input shape the state shape\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        # add fully connected layers\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear')) # provide as output the number of possible states\n",
    "        # compile model with Huber loss and RMSprop optimizer\n",
    "        model.compile(loss=Huber(), optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"Select action according to the epsilon-greedy policy\"\"\"\n",
    "        # get the correct dimension that the models accepts\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        action = self.model.predict(state)\n",
    "\n",
    "        if random.random() > self.epsilon:\n",
    "            return np.argmax(action[0]) # exploitation\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size)) # exploration\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the model using random batches of experiences from the memory\"\"\"\n",
    "        \n",
    "        # start sampling from experience when memory is filled\n",
    "        # pre-populate according to memory_size so that experiences are decorrelated to increase stability\n",
    "        if len(self.memory) >= self.memory_size:\n",
    "            states, actions, rewards, next_states, dones = self.memory.sample() # random memory sample\n",
    "            # iterate over the batch to fix dimensions\n",
    "            for i in range(len(states)):\n",
    "                state, action, reward, next_state, done = states[i], actions[i], rewards[i], next_states[i], dones[i]\n",
    "                state = np.expand_dims(state, axis=0)\n",
    "                next_state = np.expand_dims(next_state, axis=0)\n",
    "            \n",
    "            targets = self.model.predict(states)\n",
    "            target_next = self.model.predict(next_states) #DQN\n",
    "            target_vals = self.target_model.predict(next_states) #Target model\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                if dones[i]:\n",
    "                    targets[i][actions[i]] = rewards[i]\n",
    "                else:\n",
    "                    # select an action using DQN model \n",
    "                    # update using the target model\n",
    "                    a = np.argmax(target_next[i])\n",
    "                    targets[i][actions[i]] = (rewards[i] + self.gamma * (target_vals[i][a]))\n",
    "\n",
    "            \n",
    "            # fit to get get the loss of the model\n",
    "            loss = self.model.fit(states, targets, epochs=1, verbose=0).history['loss'][0]\n",
    "            return loss\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        \"\"\"Copy weights from the model used for action selection to the model used for computing targets\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def save_model(self, token=None):\n",
    "        \"\"\"Save the DQN Network\"\"\"\n",
    "        if token==None:\n",
    "            self.model.save('spaceinv_local_model.h5')\n",
    "        else:\n",
    "            self.model.save(f'spaceinv_local_model_{token}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A RANDOM AGENT \n",
    "class RandomAgent:\n",
    "    def __init__(self, action_space):\n",
    "        \"\"\"Create an instance of a random agent\"\"\"\n",
    "        self.action_size = action_space.n\n",
    "        \n",
    "    def get_action(self):\n",
    "        \"\"\"Select action uniformly at random\"\"\"\n",
    "        action = random.choice(np.arange(self.action_size))\n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE TRAINING PARAMETERS\n",
    "EPISODES = 1000 # Number of episodes\n",
    "\n",
    "cumulative_rewards = []\n",
    "\n",
    "# Get an instance of a DDQN agent\n",
    "ddqnAgent = DDQNAgent(np.shape(env.reset()),env.action_space, capacity=1000000, batch_size=64, memory_size=1000, \n",
    "                 learning_rate=0.00025, gamma = 0.99, epsilon=1.0, epsilon_min = 0.1, epsilon_decay = 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initialised...\n",
      "\n",
      "Episode 1 of 1000:\n",
      "   score: 55.0 \n",
      "   loss: None \n",
      "   ε: 0.9505613870635811 \n",
      "   time taken: 11.966 sec\n",
      "Episode 2 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: None \n",
      "   ε: 0.9063724947491544 \n",
      "   time taken: 9.887 sec\n",
      "Episode 3 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 0.09134040027856827 \n",
      "   ε: 0.8541846587479748 \n",
      "   time taken: 80.338 sec\n",
      "Episode 4 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.0014400212094187737 \n",
      "   ε: 0.7971508580312495 \n",
      "   time taken: 95.087 sec\n",
      "Episode 5 of 1000:\n",
      "   score: 210.0 \n",
      "   loss: 0.038706887513399124 \n",
      "   ε: 0.7324094444641664 \n",
      "   time taken: 116.701 sec\n",
      "Episode 6 of 1000:\n",
      "   score: 35.0 \n",
      "   loss: 5.296117524267174e-05 \n",
      "   ε: 0.6814590100757734 \n",
      "   time taken: 99.024 sec\n",
      "Episode 7 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 0.03885195404291153 \n",
      "   ε: 0.617223473725626 \n",
      "   time taken: 135.774 sec\n",
      "Episode 8 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.07565022259950638 \n",
      "   ε: 0.5764725577755621 \n",
      "   time taken: 93.821 sec\n",
      "Episode 9 of 1000:\n",
      "   score: 15.0 \n",
      "   loss: 0.014215942472219467 \n",
      "   ε: 0.5419233912758394 \n",
      "   time taken: 85.108 sec\n",
      "Episode 10 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.021050693467259407 \n",
      "   ε: 0.5086303255385652 \n",
      "   time taken: 87.093 sec\n",
      "Episode 11 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.011765939183533192 \n",
      "   ε: 0.47409985378108294 \n",
      "   time taken: 96.750 sec\n",
      "Episode 12 of 1000:\n",
      "   score: 460.0 \n",
      "   loss: 0.00015539734158664942 \n",
      "   ε: 0.41809625288452507 \n",
      "   time taken: 173.191 sec\n",
      "Episode 13 of 1000:\n",
      "   score: 405.0 \n",
      "   loss: 0.0117968013510108 \n",
      "   ε: 0.36937244855172535 \n",
      "   time taken: 170.526 sec\n",
      "Episode 14 of 1000:\n",
      "   score: 440.0 \n",
      "   loss: 5.4544048907700926e-05 \n",
      "   ε: 0.3138444042160421 \n",
      "   time taken: 224.206 sec\n",
      "Episode 15 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.00023306369257625192 \n",
      "   ε: 0.29530073859536704 \n",
      "   time taken: 83.569 sec\n",
      "Episode 16 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 0.07558613270521164 \n",
      "   ε: 0.26829563671685835 \n",
      "   time taken: 132.110 sec\n",
      "Episode 17 of 1000:\n",
      "   score: 225.0 \n",
      "   loss: 0.03788180276751518 \n",
      "   ε: 0.24856035028520188 \n",
      "   time taken: 104.884 sec\n",
      "Episode 18 of 1000:\n",
      "   score: 70.0 \n",
      "   loss: 0.01215928141027689 \n",
      "   ε: 0.23558764131025742 \n",
      "   time taken: 73.594 sec\n",
      "Episode 19 of 1000:\n",
      "   score: 720.0 \n",
      "   loss: 0.08730300515890121 \n",
      "   ε: 0.20815371137039865 \n",
      "   time taken: 170.558 sec\n",
      "Episode 20 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 9.309130837209523e-05 \n",
      "   ε: 0.19433303616664216 \n",
      "   time taken: 94.509 sec\n",
      "Episode 21 of 1000:\n",
      "   score: 325.0 \n",
      "   loss: 0.0010332062374800444 \n",
      "   ε: 0.17223629344595223 \n",
      "   time taken: 165.926 sec\n",
      "Episode 22 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.036427564918994904 \n",
      "   ε: 0.15412466343211184 \n",
      "   time taken: 152.826 sec\n",
      "Episode 23 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 8.624689507996663e-05 \n",
      "   ε: 0.14428037822958048 \n",
      "   time taken: 90.804 sec\n",
      "Episode 24 of 1000:\n",
      "   score: 430.0 \n",
      "   loss: 0.037884730845689774 \n",
      "   ε: 0.1290697437072991 \n",
      "   time taken: 153.178 sec\n",
      "Episode 25 of 1000:\n",
      "   score: 305.0 \n",
      "   loss: 7.369383820332587e-05 \n",
      "   ε: 0.11493274219242432 \n",
      "   time taken: 159.419 sec\n",
      "Episode 26 of 1000:\n",
      "   score: 240.0 \n",
      "   loss: 0.2419588267803192 \n",
      "   ε: 0.10622326647603034 \n",
      "   time taken: 108.457 sec\n",
      "Episode 27 of 1000:\n",
      "   score: 240.0 \n",
      "   loss: 9.123937343247235e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.135 sec\n",
      "Episode 28 of 1000:\n",
      "   score: 190.0 \n",
      "   loss: 0.024855978786945343 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 148.537 sec\n",
      "Episode 29 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 0.15248160064220428 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 149.249 sec\n",
      "Episode 30 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 7.269406341947615e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 156.473 sec\n",
      "Episode 31 of 1000:\n",
      "   score: 285.0 \n",
      "   loss: 0.024851148948073387 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 100.811 sec\n",
      "Episode 32 of 1000:\n",
      "   score: 215.0 \n",
      "   loss: 0.00011011588503606617 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 117.476 sec\n",
      "Episode 33 of 1000:\n",
      "   score: 210.0 \n",
      "   loss: 0.08856934309005737 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 79.782 sec\n",
      "Episode 34 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 5.210149538470432e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 96.327 sec\n",
      "Episode 35 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 7.863399514462799e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.708 sec\n",
      "Episode 36 of 1000:\n",
      "   score: 50.0 \n",
      "   loss: 0.03786256164312363 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 53.105 sec\n",
      "Episode 37 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.03791666403412819 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.822 sec\n",
      "Episode 38 of 1000:\n",
      "   score: 275.0 \n",
      "   loss: 0.0886574313044548 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.231 sec\n",
      "Episode 39 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 6.643948290729895e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 156.691 sec\n",
      "Episode 40 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 7.59507529437542e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 83.356 sec\n",
      "Episode 41 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 0.1638217568397522 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 69.261 sec\n",
      "Episode 42 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 0.11671903729438782 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 68.832 sec\n",
      "Episode 43 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 7.393175474135205e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 86.791 sec\n",
      "Episode 44 of 1000:\n",
      "   score: 295.0 \n",
      "   loss: 0.0007857875898480415 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 162.901 sec\n",
      "Episode 45 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 7.358714356087148e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 78.820 sec\n",
      "Episode 46 of 1000:\n",
      "   score: 185.0 \n",
      "   loss: 0.03795360028743744 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.218 sec\n",
      "Episode 47 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 0.011900513432919979 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.899 sec\n",
      "Episode 48 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 7.314558024518192e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.020 sec\n",
      "Episode 49 of 1000:\n",
      "   score: 340.0 \n",
      "   loss: 5.5895397963467985e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 195.853 sec\n",
      "Episode 50 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.079561248421669 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 85.898 sec\n",
      "Episode 51 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 0.12630468606948853 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.355 sec\n",
      "Episode 52 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.0888877809047699 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.902 sec\n",
      "Episode 53 of 1000:\n",
      "   score: 250.0 \n",
      "   loss: 0.06382929533720016 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.800 sec\n",
      "Episode 54 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.005707132164388895 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 146.581 sec\n",
      "Episode 55 of 1000:\n",
      "   score: 295.0 \n",
      "   loss: 0.038378581404685974 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 173.613 sec\n",
      "Episode 56 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.17142242193222046 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 124.158 sec\n",
      "Episode 57 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 0.11330795288085938 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 150.948 sec\n",
      "Episode 58 of 1000:\n",
      "   score: 15.0 \n",
      "   loss: 0.011890415102243423 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 53.173 sec\n",
      "Episode 59 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 0.050906240940093994 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 155.519 sec\n",
      "Episode 60 of 1000:\n",
      "   score: 200.0 \n",
      "   loss: 0.0033944863826036453 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 98.482 sec\n",
      "Episode 61 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.011800875887274742 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 134.412 sec\n",
      "Episode 62 of 1000:\n",
      "   score: 415.0 \n",
      "   loss: 0.13917984068393707 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 159.796 sec\n",
      "Episode 63 of 1000:\n",
      "   score: 250.0 \n",
      "   loss: 0.07680843770503998 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.486 sec\n",
      "Episode 64 of 1000:\n",
      "   score: 445.0 \n",
      "   loss: 0.023508872836828232 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 201.895 sec\n",
      "Episode 65 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.037756241858005524 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 154.509 sec\n",
      "Episode 66 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.011792161501944065 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 50.354 sec\n",
      "Episode 67 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.03784387931227684 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.101 sec\n",
      "Episode 68 of 1000:\n",
      "   score: 270.0 \n",
      "   loss: 0.024848908185958862 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 135.873 sec\n",
      "Episode 69 of 1000:\n",
      "   score: 50.0 \n",
      "   loss: 9.600972407497466e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.526 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70 of 1000:\n",
      "   score: 460.0 \n",
      "   loss: 0.24240443110466003 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 174.184 sec\n",
      "Episode 71 of 1000:\n",
      "   score: 335.0 \n",
      "   loss: 0.04777919128537178 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 151.950 sec\n",
      "Episode 72 of 1000:\n",
      "   score: 410.0 \n",
      "   loss: 0.03637773543596268 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 223.343 sec\n",
      "Episode 73 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.02735978364944458 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 78.987 sec\n",
      "Episode 74 of 1000:\n",
      "   score: 310.0 \n",
      "   loss: 9.186773240799084e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 183.490 sec\n",
      "Episode 75 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.049810830503702164 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 85.781 sec\n",
      "Episode 76 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 5.363763921195641e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 83.771 sec\n",
      "Episode 77 of 1000:\n",
      "   score: 715.0 \n",
      "   loss: 0.02480178512632847 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 241.055 sec\n",
      "Episode 78 of 1000:\n",
      "   score: 50.0 \n",
      "   loss: 8.201508899219334e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 75.402 sec\n",
      "Episode 79 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.037895046174526215 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 115.195 sec\n",
      "Episode 80 of 1000:\n",
      "   score: 225.0 \n",
      "   loss: 0.09017574042081833 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.629 sec\n",
      "Episode 81 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 0.037934377789497375 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.973 sec\n",
      "Episode 82 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 0.03786121681332588 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 85.814 sec\n",
      "Episode 83 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 0.004324084147810936 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 84.496 sec\n",
      "Episode 84 of 1000:\n",
      "   score: 285.0 \n",
      "   loss: 0.021312464028596878 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 123.367 sec\n",
      "Episode 85 of 1000:\n",
      "   score: 450.0 \n",
      "   loss: 6.42614031676203e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 148.206 sec\n",
      "Episode 86 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 9.473365207668394e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 154.536 sec\n",
      "Episode 87 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 5.6888737162807956e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 132.736 sec\n",
      "Episode 88 of 1000:\n",
      "   score: 445.0 \n",
      "   loss: 0.00010932319128187373 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 131.519 sec\n",
      "Episode 89 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.2048027366399765 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 128.838 sec\n",
      "Episode 90 of 1000:\n",
      "   score: 30.0 \n",
      "   loss: 0.00013601119280792773 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.234 sec\n",
      "Episode 91 of 1000:\n",
      "   score: 330.0 \n",
      "   loss: 0.011172769591212273 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.151 sec\n",
      "Episode 92 of 1000:\n",
      "   score: 520.0 \n",
      "   loss: 0.025294646620750427 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 170.850 sec\n",
      "Episode 93 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 7.472018478438258e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 108.394 sec\n",
      "Episode 94 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.024668456986546516 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 95.586 sec\n",
      "Episode 95 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 6.199954077601433e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 86.480 sec\n",
      "Episode 96 of 1000:\n",
      "   score: 470.0 \n",
      "   loss: 0.10697611421346664 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 131.945 sec\n",
      "Episode 97 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 0.06248492747545242 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.963 sec\n",
      "Episode 98 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 0.09019476175308228 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.115 sec\n",
      "Episode 99 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 7.555981574114412e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 178.643 sec\n",
      "Episode 100 of 1000:\n",
      "   score: 530.0 \n",
      "   loss: 5.56668674107641e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 187.504 sec\n",
      "Episode 101 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 2.780377872113604e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 163.945 sec\n",
      "Episode 102 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 0.011689169332385063 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 147.859 sec\n",
      "Episode 103 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 0.011695650406181812 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 81.732 sec\n",
      "Episode 104 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 4.206360608804971e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 67.138 sec\n",
      "Episode 105 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.0638062059879303 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 55.312 sec\n",
      "Episode 106 of 1000:\n",
      "   score: 385.0 \n",
      "   loss: 0.011690699495375156 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 146.279 sec\n",
      "Episode 107 of 1000:\n",
      "   score: 415.0 \n",
      "   loss: 1.4422434105654247e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.618 sec\n",
      "Episode 108 of 1000:\n",
      "   score: 435.0 \n",
      "   loss: 0.08851253986358643 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 152.451 sec\n",
      "Episode 109 of 1000:\n",
      "   score: 370.0 \n",
      "   loss: 0.01169507298618555 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 141.656 sec\n",
      "Episode 110 of 1000:\n",
      "   score: 80.0 \n",
      "   loss: 0.03773603215813637 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 108.015 sec\n",
      "Episode 111 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 2.7121626771986485e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 74.045 sec\n",
      "Episode 112 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 0.06243576854467392 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 120.866 sec\n",
      "Episode 113 of 1000:\n",
      "   score: 80.0 \n",
      "   loss: 3.612640284700319e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.950 sec\n",
      "Episode 114 of 1000:\n",
      "   score: 125.0 \n",
      "   loss: 3.9474121876992285e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.686 sec\n",
      "Episode 115 of 1000:\n",
      "   score: 390.0 \n",
      "   loss: 1.9933246221626177e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 156.932 sec\n",
      "Episode 116 of 1000:\n",
      "   score: 45.0 \n",
      "   loss: 1.9373490431462415e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 59.856 sec\n",
      "Episode 117 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 2.0674329789471813e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 84.118 sec\n",
      "Episode 118 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 2.5302193535026163e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 132.166 sec\n",
      "Episode 119 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 1.1017325959983282e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 106.279 sec\n",
      "Episode 120 of 1000:\n",
      "   score: 235.0 \n",
      "   loss: 0.11452989280223846 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 132.031 sec\n",
      "Episode 121 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 3.4133252484025434e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 116.160 sec\n",
      "Episode 122 of 1000:\n",
      "   score: 75.0 \n",
      "   loss: 0.024718305096030235 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.598 sec\n",
      "Episode 123 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.02472279593348503 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 112.789 sec\n",
      "Episode 124 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 0.10017190873622894 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 85.251 sec\n",
      "Episode 125 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.03636808693408966 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.551 sec\n",
      "Episode 126 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 3.3673331927275285e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.424 sec\n",
      "Episode 127 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 0.011715148575603962 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 86.185 sec\n",
      "Episode 128 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 1.0641676453815307e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.779 sec\n",
      "Episode 129 of 1000:\n",
      "   score: 310.0 \n",
      "   loss: 0.06244157999753952 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 136.084 sec\n",
      "Episode 130 of 1000:\n",
      "   score: 460.0 \n",
      "   loss: 1.5073829672473948e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 145.341 sec\n",
      "Episode 131 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 0.063786081969738 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.715 sec\n",
      "Episode 132 of 1000:\n",
      "   score: 510.0 \n",
      "   loss: 0.024731433019042015 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 261.293 sec\n",
      "Episode 133 of 1000:\n",
      "   score: 0.0 \n",
      "   loss: 0.07545119524002075 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 40.614 sec\n",
      "Episode 134 of 1000:\n",
      "   score: 395.0 \n",
      "   loss: 0.21736213564872742 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 123.782 sec\n",
      "Episode 135 of 1000:\n",
      "   score: 390.0 \n",
      "   loss: 0.06240272521972656 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 147.818 sec\n",
      "Episode 136 of 1000:\n",
      "   score: 5.0 \n",
      "   loss: 0.011717824265360832 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 66.599 sec\n",
      "Episode 137 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.050771284848451614 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.248 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.07547308504581451 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.356 sec\n",
      "Episode 139 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 2.2494790755445138e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 126.736 sec\n",
      "Episode 140 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 0.02471933700144291 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.343 sec\n",
      "Episode 141 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 4.0281465771840885e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 71.310 sec\n",
      "Episode 142 of 1000:\n",
      "   score: 395.0 \n",
      "   loss: 2.1380550606409088e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 176.365 sec\n",
      "Episode 143 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 6.822325758548686e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 69.368 sec\n",
      "Episode 144 of 1000:\n",
      "   score: 295.0 \n",
      "   loss: 2.3025473637972027e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 209.804 sec\n",
      "Episode 145 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 0.03636898472905159 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.889 sec\n",
      "Episode 146 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 0.06377729773521423 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.999 sec\n",
      "Episode 147 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 3.9451144402846694e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.537 sec\n",
      "Episode 148 of 1000:\n",
      "   score: 270.0 \n",
      "   loss: 0.06378795206546783 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 190.513 sec\n",
      "Episode 149 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 0.011694563552737236 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 130.678 sec\n",
      "Episode 150 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 0.07546086609363556 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 78.114 sec\n",
      "Episode 151 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 0.07682923227548599 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 103.377 sec\n",
      "Episode 152 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 3.516183642204851e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.197 sec\n",
      "Episode 153 of 1000:\n",
      "   score: 310.0 \n",
      "   loss: 2.6170262572122738e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 141.539 sec\n",
      "Episode 154 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 0.10149894654750824 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 132.811 sec\n",
      "Episode 155 of 1000:\n",
      "   score: 315.0 \n",
      "   loss: 0.139192596077919 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 123.454 sec\n",
      "Episode 156 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 0.03641360625624657 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 121.438 sec\n",
      "Episode 157 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 2.5479766918579116e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 112.319 sec\n",
      "Episode 158 of 1000:\n",
      "   score: 300.0 \n",
      "   loss: 0.13920149207115173 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 144.379 sec\n",
      "Episode 159 of 1000:\n",
      "   score: 200.0 \n",
      "   loss: 0.07683827728033066 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 155.579 sec\n",
      "Episode 160 of 1000:\n",
      "   score: 470.0 \n",
      "   loss: 0.1262272298336029 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 134.106 sec\n",
      "Episode 161 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 0.10008720308542252 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 106.392 sec\n",
      "Episode 162 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 0.03510512039065361 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 135.367 sec\n",
      "Episode 163 of 1000:\n",
      "   score: 185.0 \n",
      "   loss: 0.011694224551320076 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 146.708 sec\n",
      "Episode 164 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.02471555955708027 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 70.804 sec\n",
      "Episode 165 of 1000:\n",
      "   score: 80.0 \n",
      "   loss: 3.072026447625831e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 83.322 sec\n",
      "Episode 166 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 2.396954187133815e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 95.141 sec\n",
      "Episode 167 of 1000:\n",
      "   score: 185.0 \n",
      "   loss: 0.023383868858218193 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 98.604 sec\n",
      "Episode 168 of 1000:\n",
      "   score: 400.0 \n",
      "   loss: 0.10148442536592484 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 157.907 sec\n",
      "Episode 169 of 1000:\n",
      "   score: 235.0 \n",
      "   loss: 0.06239326298236847 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 122.392 sec\n",
      "Episode 170 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 0.03774029016494751 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 156.739 sec\n",
      "Episode 171 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 1.9747891201404855e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.631 sec\n",
      "Episode 172 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.023394616320729256 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.024 sec\n",
      "Episode 173 of 1000:\n",
      "   score: 50.0 \n",
      "   loss: 0.10147813707590103 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 53.490 sec\n",
      "Episode 174 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.06378540396690369 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 143.000 sec\n",
      "Episode 175 of 1000:\n",
      "   score: 330.0 \n",
      "   loss: 0.05076208710670471 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 120.677 sec\n",
      "Episode 176 of 1000:\n",
      "   score: 40.0 \n",
      "   loss: 2.8742666472680867e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 81.125 sec\n",
      "Episode 177 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.11317317187786102 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 101.943 sec\n",
      "Episode 178 of 1000:\n",
      "   score: 215.0 \n",
      "   loss: 0.07545250654220581 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.841 sec\n",
      "Episode 179 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.04945863038301468 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.178 sec\n",
      "Episode 180 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 0.11453744024038315 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 81.618 sec\n",
      "Episode 181 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 1.3177005712350365e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 68.784 sec\n",
      "Episode 182 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 5.495224831975065e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 129.938 sec\n",
      "Episode 183 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 0.11452316492795944 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 86.175 sec\n",
      "Episode 184 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.06245531514286995 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 70.215 sec\n",
      "Episode 185 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 3.1082265195436776e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.182 sec\n",
      "Episode 186 of 1000:\n",
      "   score: 455.0 \n",
      "   loss: 0.037741370499134064 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 159.220 sec\n",
      "Episode 187 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 0.050774652510881424 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 116.359 sec\n",
      "Episode 188 of 1000:\n",
      "   score: 225.0 \n",
      "   loss: 0.07546719908714294 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 145.683 sec\n",
      "Episode 189 of 1000:\n",
      "   score: 480.0 \n",
      "   loss: 0.08849267661571503 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 186.967 sec\n",
      "Episode 190 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 0.03773709386587143 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.069 sec\n",
      "Episode 191 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 0.1508936583995819 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 77.605 sec\n",
      "Episode 192 of 1000:\n",
      "   score: 250.0 \n",
      "   loss: 0.024726154282689095 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.421 sec\n",
      "Episode 193 of 1000:\n",
      "   score: 70.0 \n",
      "   loss: 0.049416013062000275 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 50.653 sec\n",
      "Episode 194 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 0.062443967908620834 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 54.039 sec\n",
      "Episode 195 of 1000:\n",
      "   score: 95.0 \n",
      "   loss: 4.790445927937981e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.109 sec\n",
      "Episode 196 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.0494333952665329 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 69.099 sec\n",
      "Episode 197 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 0.011702307499945164 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 137.832 sec\n",
      "Episode 198 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 0.037735164165496826 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.085 sec\n",
      "Episode 199 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 0.037740446627140045 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 79.921 sec\n",
      "Episode 200 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 3.706233110278845e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 110.601 sec\n",
      "Episode 201 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 0.01171016599982977 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.054 sec\n",
      "Episode 202 of 1000:\n",
      "   score: 325.0 \n",
      "   loss: 0.024730153381824493 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 126.180 sec\n",
      "Episode 203 of 1000:\n",
      "   score: 185.0 \n",
      "   loss: 0.13923192024230957 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 78.764 sec\n",
      "Episode 204 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 1.679682100075297e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 95.120 sec\n",
      "Episode 205 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 2.3089411115506664e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 110.867 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 206 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.10146962106227875 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 111.867 sec\n",
      "Episode 207 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 9.214591409545392e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.053 sec\n",
      "Episode 208 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 2.657204822753556e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.876 sec\n",
      "Episode 209 of 1000:\n",
      "   score: 550.0 \n",
      "   loss: 0.12619462609291077 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 160.412 sec\n",
      "Episode 210 of 1000:\n",
      "   score: 185.0 \n",
      "   loss: 2.37660115089966e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 116.158 sec\n",
      "Episode 211 of 1000:\n",
      "   score: 320.0 \n",
      "   loss: 0.011688273400068283 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 130.609 sec\n",
      "Episode 212 of 1000:\n",
      "   score: 400.0 \n",
      "   loss: 0.036441437900066376 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 119.718 sec\n",
      "Episode 213 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 0.011691864579916 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.969 sec\n",
      "Episode 214 of 1000:\n",
      "   score: 275.0 \n",
      "   loss: 2.6650508516468108e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.482 sec\n",
      "Episode 215 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 0.011707339435815811 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 82.174 sec\n",
      "Episode 216 of 1000:\n",
      "   score: 295.0 \n",
      "   loss: 0.011706383898854256 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 119.246 sec\n",
      "Episode 217 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 1.1463725968496874e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.143 sec\n",
      "Episode 218 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 0.06108187139034271 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 69.602 sec\n",
      "Episode 219 of 1000:\n",
      "   score: 285.0 \n",
      "   loss: 0.10147708654403687 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 146.175 sec\n",
      "Episode 220 of 1000:\n",
      "   score: 460.0 \n",
      "   loss: 0.011704864911735058 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 195.432 sec\n",
      "Episode 221 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 2.35270108532859e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.993 sec\n",
      "Episode 222 of 1000:\n",
      "   score: 385.0 \n",
      "   loss: 5.7586290495237336e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 176.782 sec\n",
      "Episode 223 of 1000:\n",
      "   score: 415.0 \n",
      "   loss: 2.3216434783535078e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 179.669 sec\n",
      "Episode 224 of 1000:\n",
      "   score: 210.0 \n",
      "   loss: 0.03775304555892944 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 146.244 sec\n",
      "Episode 225 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 3.6466917663346976e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 121.812 sec\n",
      "Episode 226 of 1000:\n",
      "   score: 75.0 \n",
      "   loss: 0.04940246045589447 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 73.661 sec\n",
      "Episode 227 of 1000:\n",
      "   score: 125.0 \n",
      "   loss: 0.11317698657512665 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 57.873 sec\n",
      "Episode 228 of 1000:\n",
      "   score: 415.0 \n",
      "   loss: 3.596791793825105e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 184.654 sec\n",
      "Episode 229 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 1.2514959962572902e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 99.358 sec\n",
      "Episode 230 of 1000:\n",
      "   score: 335.0 \n",
      "   loss: 3.377018583705649e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 134.718 sec\n",
      "Episode 231 of 1000:\n",
      "   score: 275.0 \n",
      "   loss: 0.011695493012666702 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 148.568 sec\n",
      "Episode 232 of 1000:\n",
      "   score: 270.0 \n",
      "   loss: 0.02471047453582287 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 151.218 sec\n",
      "Episode 233 of 1000:\n",
      "   score: 365.0 \n",
      "   loss: 2.113658956659492e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 96.430 sec\n",
      "Episode 234 of 1000:\n",
      "   score: 225.0 \n",
      "   loss: 3.081086470047012e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 96.811 sec\n",
      "Episode 235 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 0.10148994624614716 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.014 sec\n",
      "Episode 236 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 0.13924284279346466 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.952 sec\n",
      "Episode 237 of 1000:\n",
      "   score: 45.0 \n",
      "   loss: 0.07679794728755951 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 70.799 sec\n",
      "Episode 238 of 1000:\n",
      "   score: 70.0 \n",
      "   loss: 0.01170719601213932 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 80.040 sec\n",
      "Episode 239 of 1000:\n",
      "   score: 210.0 \n",
      "   loss: 0.011686445213854313 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.198 sec\n",
      "Episode 240 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 2.987696643685922e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.234 sec\n",
      "Episode 241 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 2.751265128608793e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.826 sec\n",
      "Episode 242 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.0768004059791565 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 93.431 sec\n",
      "Episode 243 of 1000:\n",
      "   score: 125.0 \n",
      "   loss: 0.011709926649928093 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.573 sec\n",
      "Episode 244 of 1000:\n",
      "   score: 315.0 \n",
      "   loss: 0.06379476189613342 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 129.872 sec\n",
      "Episode 245 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 4.9519530875841156e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 140.515 sec\n",
      "Episode 246 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.03773149847984314 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 55.273 sec\n",
      "Episode 247 of 1000:\n",
      "   score: 280.0 \n",
      "   loss: 0.024742092937231064 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 136.774 sec\n",
      "Episode 248 of 1000:\n",
      "   score: 125.0 \n",
      "   loss: 2.2116746549727395e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.388 sec\n",
      "Episode 249 of 1000:\n",
      "   score: 215.0 \n",
      "   loss: 0.02470780722796917 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 108.800 sec\n",
      "Episode 250 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 0.011711419560015202 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.628 sec\n",
      "Episode 251 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.08575324714183807 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.073 sec\n",
      "Episode 252 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 4.960061778547242e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.358 sec\n",
      "Episode 253 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 2.1089685105835088e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.901 sec\n",
      "Episode 254 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 2.1632689822581597e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 72.320 sec\n",
      "Episode 255 of 1000:\n",
      "   score: 385.0 \n",
      "   loss: 0.1755799949169159 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 103.471 sec\n",
      "Episode 256 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 0.05074477940797806 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 171.200 sec\n",
      "Episode 257 of 1000:\n",
      "   score: 110.0 \n",
      "   loss: 0.10150798410177231 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.955 sec\n",
      "Episode 258 of 1000:\n",
      "   score: 190.0 \n",
      "   loss: 0.00012136645818827674 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.307 sec\n",
      "Episode 259 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.011718274094164371 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 113.521 sec\n",
      "Episode 260 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 6.256815140659455e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 73.183 sec\n",
      "Episode 261 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.05076043680310249 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 69.230 sec\n",
      "Episode 262 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 0.06376605480909348 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 109.191 sec\n",
      "Episode 263 of 1000:\n",
      "   score: 340.0 \n",
      "   loss: 0.07406200468540192 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 188.332 sec\n",
      "Episode 264 of 1000:\n",
      "   score: 335.0 \n",
      "   loss: 0.04939689487218857 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.175 sec\n",
      "Episode 265 of 1000:\n",
      "   score: 310.0 \n",
      "   loss: 0.08850225806236267 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 141.437 sec\n",
      "Episode 266 of 1000:\n",
      "   score: 75.0 \n",
      "   loss: 0.024719079956412315 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 95.361 sec\n",
      "Episode 267 of 1000:\n",
      "   score: 215.0 \n",
      "   loss: 0.05078273266553879 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 128.141 sec\n",
      "Episode 268 of 1000:\n",
      "   score: 415.0 \n",
      "   loss: 0.050771523267030716 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 190.558 sec\n",
      "Episode 269 of 1000:\n",
      "   score: 80.0 \n",
      "   loss: 0.024713406339287758 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 86.278 sec\n",
      "Episode 270 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 0.024719923734664917 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 111.944 sec\n",
      "Episode 271 of 1000:\n",
      "   score: 285.0 \n",
      "   loss: 0.06109080836176872 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 152.770 sec\n",
      "Episode 272 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 2.320078419870697e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 88.348 sec\n",
      "Episode 273 of 1000:\n",
      "   score: 90.0 \n",
      "   loss: 6.248745194170624e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 99.608 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 274 of 1000:\n",
      "   score: 710.0 \n",
      "   loss: 0.011699065566062927 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 179.683 sec\n",
      "Episode 275 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 2.4690296413609758e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.499 sec\n",
      "Episode 276 of 1000:\n",
      "   score: 365.0 \n",
      "   loss: 0.06243904307484627 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 176.792 sec\n",
      "Episode 277 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 0.050765641033649445 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 162.898 sec\n",
      "Episode 278 of 1000:\n",
      "   score: 45.0 \n",
      "   loss: 0.03773793578147888 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 71.844 sec\n",
      "Episode 279 of 1000:\n",
      "   score: 270.0 \n",
      "   loss: 0.06378994882106781 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.932 sec\n",
      "Episode 280 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 1.2538328519440256e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 89.841 sec\n",
      "Episode 281 of 1000:\n",
      "   score: 80.0 \n",
      "   loss: 0.0611126683652401 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 74.857 sec\n",
      "Episode 282 of 1000:\n",
      "   score: 100.0 \n",
      "   loss: 0.036366529762744904 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.576 sec\n",
      "Episode 283 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 4.79475456813816e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 108.878 sec\n",
      "Episode 284 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.049420055001974106 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.620 sec\n",
      "Episode 285 of 1000:\n",
      "   score: 215.0 \n",
      "   loss: 4.524125688476488e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 84.917 sec\n",
      "Episode 286 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.02471342869102955 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 87.878 sec\n",
      "Episode 287 of 1000:\n",
      "   score: 355.0 \n",
      "   loss: 0.04940341040492058 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 178.517 sec\n",
      "Episode 288 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.10015493631362915 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.301 sec\n",
      "Episode 289 of 1000:\n",
      "   score: 495.0 \n",
      "   loss: 0.024724703282117844 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 151.952 sec\n",
      "Episode 290 of 1000:\n",
      "   score: 190.0 \n",
      "   loss: 0.1262028068304062 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.472 sec\n",
      "Episode 291 of 1000:\n",
      "   score: 345.0 \n",
      "   loss: 0.011706216260790825 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 170.368 sec\n",
      "Episode 292 of 1000:\n",
      "   score: 150.0 \n",
      "   loss: 2.165154910471756e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.659 sec\n",
      "Episode 293 of 1000:\n",
      "   score: 345.0 \n",
      "   loss: 0.1261870115995407 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 98.959 sec\n",
      "Episode 294 of 1000:\n",
      "   score: 265.0 \n",
      "   loss: 0.03772739693522453 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 142.501 sec\n",
      "Episode 295 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 0.07681666314601898 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.322 sec\n",
      "Episode 296 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 4.9607377150096e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 136.485 sec\n",
      "Episode 297 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.11315377056598663 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 138.940 sec\n",
      "Episode 298 of 1000:\n",
      "   score: 85.0 \n",
      "   loss: 5.824636900797486e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 71.126 sec\n",
      "Episode 299 of 1000:\n",
      "   score: 50.0 \n",
      "   loss: 0.061087388545274734 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 70.579 sec\n",
      "Episode 300 of 1000:\n",
      "   score: 280.0 \n",
      "   loss: 3.259658842580393e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 152.654 sec\n",
      "Episode 301 of 1000:\n",
      "   score: 270.0 \n",
      "   loss: 2.439180389046669e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.224 sec\n",
      "Episode 302 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 0.011696279980242252 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 115.252 sec\n",
      "Episode 303 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 2.5565670512150973e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 135.915 sec\n",
      "Episode 304 of 1000:\n",
      "   score: 675.0 \n",
      "   loss: 0.06380423158407211 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 171.398 sec\n",
      "Episode 305 of 1000:\n",
      "   score: 240.0 \n",
      "   loss: 4.2637475416995585e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.728 sec\n",
      "Episode 306 of 1000:\n",
      "   score: 255.0 \n",
      "   loss: 0.03641257807612419 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 128.878 sec\n",
      "Episode 307 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 2.352664159843698e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 109.307 sec\n",
      "Episode 308 of 1000:\n",
      "   score: 235.0 \n",
      "   loss: 0.05077594891190529 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 132.898 sec\n",
      "Episode 309 of 1000:\n",
      "   score: 335.0 \n",
      "   loss: 0.04940827190876007 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 140.858 sec\n",
      "Episode 310 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 5.256391523289494e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.029 sec\n",
      "Episode 311 of 1000:\n",
      "   score: 310.0 \n",
      "   loss: 0.024719610810279846 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 165.735 sec\n",
      "Episode 312 of 1000:\n",
      "   score: 575.0 \n",
      "   loss: 0.11450114846229553 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 137.182 sec\n",
      "Episode 313 of 1000:\n",
      "   score: 130.0 \n",
      "   loss: 0.12489364296197891 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 108.982 sec\n",
      "Episode 314 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 0.1508849859237671 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 178.908 sec\n",
      "Episode 315 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.06380440294742584 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 124.882 sec\n",
      "Episode 316 of 1000:\n",
      "   score: 95.0 \n",
      "   loss: 4.388227898743935e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 73.192 sec\n",
      "Episode 317 of 1000:\n",
      "   score: 410.0 \n",
      "   loss: 0.06379228830337524 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 155.677 sec\n",
      "Episode 318 of 1000:\n",
      "   score: 160.0 \n",
      "   loss: 1.2559554306790233e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 94.170 sec\n",
      "Episode 319 of 1000:\n",
      "   score: 315.0 \n",
      "   loss: 3.7794714444316924e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 158.872 sec\n",
      "Episode 320 of 1000:\n",
      "   score: 205.0 \n",
      "   loss: 0.01169076282531023 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.040 sec\n",
      "Episode 321 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 2.8661510441452265e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 118.016 sec\n",
      "Episode 322 of 1000:\n",
      "   score: 395.0 \n",
      "   loss: 0.06103973463177681 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 210.207 sec\n",
      "Episode 323 of 1000:\n",
      "   score: 35.0 \n",
      "   loss: 0.03776095435023308 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 91.073 sec\n",
      "Episode 324 of 1000:\n",
      "   score: 395.0 \n",
      "   loss: 0.037742044776678085 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 138.682 sec\n",
      "Episode 325 of 1000:\n",
      "   score: 235.0 \n",
      "   loss: 6.396726530510932e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 130.001 sec\n",
      "Episode 326 of 1000:\n",
      "   score: 235.0 \n",
      "   loss: 0.024724164977669716 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 128.636 sec\n",
      "Episode 327 of 1000:\n",
      "   score: 200.0 \n",
      "   loss: 0.02478788234293461 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 95.536 sec\n",
      "Episode 328 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 0.06377924978733063 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 99.014 sec\n",
      "Episode 329 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 5.906011938350275e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 84.936 sec\n",
      "Episode 330 of 1000:\n",
      "   score: 380.0 \n",
      "   loss: 6.26536930212751e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 126.396 sec\n",
      "Episode 331 of 1000:\n",
      "   score: 70.0 \n",
      "   loss: 0.011697279289364815 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 74.214 sec\n",
      "Episode 332 of 1000:\n",
      "   score: 135.0 \n",
      "   loss: 0.0610877126455307 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.392 sec\n",
      "Episode 333 of 1000:\n",
      "   score: 395.0 \n",
      "   loss: 2.527919423300773e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 133.500 sec\n",
      "Episode 334 of 1000:\n",
      "   score: 175.0 \n",
      "   loss: 2.3373269868898205e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 98.089 sec\n",
      "Episode 335 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 0.03637712448835373 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.400 sec\n",
      "Episode 336 of 1000:\n",
      "   score: 475.0 \n",
      "   loss: 0.1275417059659958 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 236.316 sec\n",
      "Episode 337 of 1000:\n",
      "   score: 255.0 \n",
      "   loss: 0.023397905752062798 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 112.248 sec\n",
      "Episode 338 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.02474156767129898 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.256 sec\n",
      "Episode 339 of 1000:\n",
      "   score: 170.0 \n",
      "   loss: 2.300671076227445e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 98.873 sec\n",
      "Episode 340 of 1000:\n",
      "   score: 250.0 \n",
      "   loss: 0.08844798803329468 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 158.897 sec\n",
      "Episode 341 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 2.008507181017194e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 165.656 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 342 of 1000:\n",
      "   score: 440.0 \n",
      "   loss: 0.10148261487483978 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 189.298 sec\n",
      "Episode 343 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.050757795572280884 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 102.561 sec\n",
      "Episode 344 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 3.798476973315701e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 64.371 sec\n",
      "Episode 345 of 1000:\n",
      "   score: 360.0 \n",
      "   loss: 0.011702603660523891 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 153.771 sec\n",
      "Episode 346 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 0.08847763389348984 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.759 sec\n",
      "Episode 347 of 1000:\n",
      "   score: 345.0 \n",
      "   loss: 3.581973578548059e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 163.168 sec\n",
      "Episode 348 of 1000:\n",
      "   score: 500.0 \n",
      "   loss: 6.157752068247646e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 142.266 sec\n",
      "Episode 349 of 1000:\n",
      "   score: 260.0 \n",
      "   loss: 0.04941888526082039 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 145.182 sec\n",
      "Episode 350 of 1000:\n",
      "   score: 585.0 \n",
      "   loss: 0.03500208631157875 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 246.088 sec\n",
      "Episode 351 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 2.7187899831915274e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 192.368 sec\n",
      "Episode 352 of 1000:\n",
      "   score: 450.0 \n",
      "   loss: 0.08849890530109406 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 195.755 sec\n",
      "Episode 353 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 1.0895282684941776e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 100.005 sec\n",
      "Episode 354 of 1000:\n",
      "   score: 480.0 \n",
      "   loss: 0.011695909313857555 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 292.773 sec\n",
      "Episode 355 of 1000:\n",
      "   score: 245.0 \n",
      "   loss: 1.9969851564383134e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 112.430 sec\n",
      "Episode 356 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 0.011718443594872952 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 106.414 sec\n",
      "Episode 357 of 1000:\n",
      "   score: 225.0 \n",
      "   loss: 0.024731485173106194 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 126.731 sec\n",
      "Episode 358 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 2.5830306185525842e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 135.841 sec\n",
      "Episode 359 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 0.12479628622531891 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 65.894 sec\n",
      "Episode 360 of 1000:\n",
      "   score: 120.0 \n",
      "   loss: 0.03639628738164902 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 57.617 sec\n",
      "Episode 361 of 1000:\n",
      "   score: 325.0 \n",
      "   loss: 0.11451618373394012 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 195.695 sec\n",
      "Episode 362 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 3.405932511668652e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 90.849 sec\n",
      "Episode 363 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.06243631988763809 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 101.267 sec\n",
      "Episode 364 of 1000:\n",
      "   score: 140.0 \n",
      "   loss: 4.762840035255067e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 106.781 sec\n",
      "Episode 365 of 1000:\n",
      "   score: 155.0 \n",
      "   loss: 0.07547537237405777 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 164.065 sec\n",
      "Episode 366 of 1000:\n",
      "   score: 105.0 \n",
      "   loss: 0.01168856117874384 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 92.988 sec\n",
      "Episode 367 of 1000:\n",
      "   score: 445.0 \n",
      "   loss: 2.7650872652884573e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 178.001 sec\n",
      "Episode 368 of 1000:\n",
      "   score: 365.0 \n",
      "   loss: 3.4334058000240475e-05 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 149.375 sec\n",
      "Episode 369 of 1000:\n",
      "   score: 200.0 \n",
      "   loss: 0.12619537115097046 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 134.678 sec\n",
      "Episode 370 of 1000:\n",
      "   score: 145.0 \n",
      "   loss: 0.023394735530018806 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 138.770 sec\n",
      "Episode 371 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.011695845052599907 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 136.398 sec\n",
      "Episode 372 of 1000:\n",
      "   score: 230.0 \n",
      "   loss: 0.024723242968320847 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 112.146 sec\n",
      "Episode 373 of 1000:\n",
      "   score: 65.0 \n",
      "   loss: 0.1508757770061493 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 59.528 sec\n",
      "Episode 374 of 1000:\n",
      "   score: 115.0 \n",
      "   loss: 0.024713782593607903 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 97.157 sec\n",
      "Episode 375 of 1000:\n",
      "   score: 200.0 \n",
      "   loss: 0.05076620355248451 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 101.821 sec\n",
      "Episode 376 of 1000:\n",
      "   score: 255.0 \n",
      "   loss: 0.024717995896935463 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 117.680 sec\n",
      "Episode 377 of 1000:\n",
      "   score: 180.0 \n",
      "   loss: 0.050805553793907166 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 120.397 sec\n",
      "Episode 378 of 1000:\n",
      "   score: 220.0 \n",
      "   loss: 0.011712172068655491 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 115.365 sec\n",
      "Episode 379 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 7.604357506352244e-06 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 173.620 sec\n",
      "Episode 380 of 1000:\n",
      "   score: 165.0 \n",
      "   loss: 0.011709394864737988 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 109.125 sec\n",
      "Episode 381 of 1000:\n",
      "   score: 60.0 \n",
      "   loss: 0.01169922947883606 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 55.396 sec\n",
      "Episode 382 of 1000:\n",
      "   score: 195.0 \n",
      "   loss: 0.011718631722033024 \n",
      "   ε: 0.0999969960769904 \n",
      "   time taken: 134.874 sec\n"
     ]
    }
   ],
   "source": [
    "## TRAIN THE DDQN AGENT\n",
    "print('Training initialised...\\n')\n",
    "for episode in range(1, EPISODES+1):\n",
    "    step = 0\n",
    "    init_time = time()\n",
    "    state = env.reset()\n",
    "    C = 0.1*EPISODES # target update step\n",
    "    ep_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = ddqnAgent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        ddqnAgent.memory.push(state, action, reward, next_state, done)\n",
    "        ep_reward += reward\n",
    "\n",
    "        if done:\n",
    "            cumulative_rewards.append(ep_reward)\n",
    "            if episode % C == 0:\n",
    "                ddqnAgent.update_target_model()\n",
    "            time_taken = time() - init_time # time taken to complete one episode                \n",
    "            print('Episode {} of {}:\\n   score: {} \\n   loss: {} \\n   \\u03B5: {} \\n   time taken: {:.3f} sec'.format(episode, EPISODES, ep_reward, loss, ddqnAgent.epsilon, time_taken))\n",
    "            break\n",
    "        else:\n",
    "            if ddqnAgent.epsilon >= ddqnAgent.epsilon_min: \n",
    "                ddqnAgent.epsilon *= ddqnAgent.epsilon_decay # decaying exploration/exploitation\n",
    "            \n",
    "            state = next_state\n",
    "\n",
    "            loss = ddqnAgent.train_model()\n",
    "    if episode % 100 == 0:\n",
    "        ddqnAgent.save_model(episode)\n",
    "        \n",
    "    # save best model so far\n",
    "    if ep_reward == max(cumulative_rewards):\n",
    "        ddqnAgent.save_model() \n",
    "    \n",
    "\n",
    "        \n",
    "print('\\nTraining ended.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TIME-PROGRESSION INDEX\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Cumulative Reward per episode\n",
    "plt.plot(cumulative_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Cumulative Reward per Episode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVALUATE THE TRAINED DDQN AGENT AGAINST A RANDOM AGENT\n",
    "saved_model = 'spaceinv_local_model.h5'\n",
    "DDQN_score = []\n",
    "test_agent = load_model(saved_model)\n",
    "RAND_score = []\n",
    "RAND_agent = RandomAgent(env.action_space)\n",
    "runs = 1\n",
    "\n",
    "# Run the trained agent for one episode\n",
    "for run in range(1,runs+1):\n",
    "    state = env.reset()\n",
    "    state = np.expand_dims(state, axis=0)\n",
    "    ep_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = test_agent.predict(state)\n",
    "        a = np.argmax(action[0])\n",
    "        env.render()\n",
    "        next_state, reward, done, info = env.step(a)\n",
    "        ep_reward += reward\n",
    "        state = next_state\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "    DDQN_score.append(ep_reward)    \n",
    "    env.close()\n",
    "\n",
    "# Run the random agent for one episode\n",
    "for run in range(1,runs+1):\n",
    "    state = env.reset()\n",
    "    ep_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = RAND_agent.get_action()\n",
    "        env.render()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        ep_reward += reward\n",
    "        state = next_state\n",
    "    RAND_score.append(ep_reward)    \n",
    "    env.close()\n",
    "\n",
    "print('Trained agent score: {}, Random agent score: {}'.format(DDQN_score,RAND_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
